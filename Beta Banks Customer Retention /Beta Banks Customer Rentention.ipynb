{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Banks Customer Retention\n",
    "Prepared by Raphael Lu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, confusion_matrix, make_scorer\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from: ../datasets/Churn.csv\n"
     ]
    }
   ],
   "source": [
    "filename = 'Churn.csv'\n",
    "paths = [\n",
    "    Path('../datasets'),\n",
    "    Path.home() / 'Documents/Triple Ten Projects/my-portfolio/datasets'  # local fallback\n",
    "]\n",
    "\n",
    "loaded_from = None  # to store the path that worked\n",
    "\n",
    "for path in paths:\n",
    "    file_path = path / filename\n",
    "    if file_path.exists():\n",
    "        df = pd.read_csv(file_path)\n",
    "        loaded_from = file_path  # save the path\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(f\"{filename} not found in any of the specified paths.\")\n",
    "\n",
    "print(f\"Data loaded from: {loaded_from}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The purpose of this project is to assess the churn of bank customers at Beta Banks. Specifically, we will train models on data of past client behaviors to predict retention or loss of customers. \n",
    "\n",
    "Because we are dealing with a binary outcome (loss v retention), we will explore random decision trees using `RandomForestClassifier` from the `sklearn` library. In training our model, we will split available data using a 3:1:1 (train : validate : test) ratio. Paramters we will explore include n_estimators, tree depth, class balance, and threshold for positive prediction. We set our determinant for accuracy of the final model a priori at an F1 Score of 0.59.\n",
    "\n",
    "Building a model that accurately predicts churn, will allow us to target customers for rention efforts.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Documentation Guide\n",
    "\n",
    "**Features**\n",
    "`RowNumber` — data string index  \n",
    "`CustomerId` — unique customer identifier  \n",
    "`Surname` — surname  \n",
    "`CreditScore` — credit score  \n",
    "`Geography` — country of residence  \n",
    "`Gender` — gender  \n",
    "`Age` — age  \n",
    "`Tenure` — period of maturation for a customer’s fixed deposit (years)  \n",
    "`Balance` — account balance  \n",
    "`NumOfProducts` — number of banking products used by the customer  \n",
    "`HasCrCard` — customer has a credit card (1 — yes, 0 — no)  \n",
    "`IsActiveMember` — customer’s activeness (1 — active, 0 — inactive)  \n",
    "`EstimatedSalary` — estimated salary\n",
    "\n",
    "**Target**  \n",
    "`Exited` — customer has left\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Exploration of Data\n",
    "\n",
    "Per initial view, we have historic data on 10,000 customers. Looking at our target metric, we see a class imbalance where only 20.4% of customers ended up leaving the bank.  \n",
    "\n",
    "`RowNumber`, `CustomerId`, and `Surname` will be removed from the data set as they are not predictive of customer churn.  \n",
    "\n",
    "`Gender`(k=2) and `Geography`(k=3) will be re-encoded using One Hot Encoding, dropping one class from each to avoid a \"Dummy Feature Trap\". \n",
    "\n",
    "In the data, we are also missing tenure information on 909 customers. Ostensibly there does not appear to specific shared characteristics amongst these individuals, however more exploration may need to be done. For the purposes if this analysis, NaN Tenure customers will be treated as a seperate category, with regard to tenure. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "50%      100193.915000      0.000000  \n",
       "min          11.580000      0.000000  \n",
       "std       57510.492818      0.402769  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Tenure</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Customer_Count</th>\n",
       "      <td>382.000</td>\n",
       "      <td>952.000</td>\n",
       "      <td>950.000</td>\n",
       "      <td>928.000</td>\n",
       "      <td>885.000</td>\n",
       "      <td>927.000</td>\n",
       "      <td>881.000</td>\n",
       "      <td>925.000</td>\n",
       "      <td>933.000</td>\n",
       "      <td>882.00</td>\n",
       "      <td>446.000</td>\n",
       "      <td>909.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exit_Rate</th>\n",
       "      <td>0.236</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Tenure             0.0      1.0      2.0      3.0      4.0      5.0      6.0   \\\n",
       "Customer_Count  382.000  952.000  950.000  928.000  885.000  927.000  881.000   \n",
       "Exit_Rate         0.236    0.224    0.195    0.213    0.208    0.202    0.201   \n",
       "\n",
       "Tenure             7.0      8.0     9.0      10.0     NaN   \n",
       "Customer_Count  925.000  933.000  882.00  446.000  909.000  \n",
       "Exit_Rate         0.173    0.186    0.22    0.206    0.201  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info())\n",
    "display(df.describe().iloc[[0,1,5,3,2,7]])\n",
    "\n",
    "tenure_analysis = df.groupby('Tenure', dropna=False)['Exited'].agg(['count', 'mean'])\n",
    "tenure_analysis.columns = ['Customer_Count', 'Exit_Rate']\n",
    "tenure_analysis['Exit_Rate'] = tenure_analysis['Exit_Rate'].round(3)\n",
    "display(tenure_analysis.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catagorical Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Unique Geographic Regions: ['France' 'Spain' 'Germany']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique Genders: ['Female' 'Male']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display (f\"Unique Geographic Regions: {df['Geography'].unique()}\")\n",
    "display (f\"Unique Genders: {df['Gender'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of `NaN` values in Tenure\n",
    "\n",
    "We will assess whether there is a statistically significant difference between the proportion of customers who have left the bank looking at customers with `NaN` Tenure years and customers with known Tenure years. For proportion comparison, we will use a Two-proportion Z-test and will set our hypotheses accordingly. We will set our alpha for statitical significance at 0.05. \n",
    "* H_0: There is no statistically significant difference between the proportions of customers who left the bank from Nan Tenure and Known Tenure\n",
    "* H_A: There is a statistically significant difference between the proportions of customers who left the bank from Nan Tenure and Known Tenure.\n",
    "\n",
    "\\* For simplicity we did not use Chi-square analysis to assess differnce amongst all tenure years. Ostensibly, all tenure years appear to have ~20% churn rate so we assumed homogenaity amongst these years.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Stat: -0.18685086273175583, P-score: 0.8517775664261061\n"
     ]
    }
   ],
   "source": [
    "group_nan = df[df['Tenure'].isna()]\n",
    "group_non_nan = df[df['Tenure'].notna()]\n",
    "\n",
    "churn_counts = np.array([group_nan['Exited'].sum(), \n",
    "                        group_non_nan['Exited'].sum()\n",
    "                       ])\n",
    "\n",
    "n_obs = np.array([len(group_nan),\n",
    "                 len(group_non_nan)\n",
    "                ])\n",
    "\n",
    "stat, pval = proportions_ztest(churn_counts, n_obs, alternative='two-sided')\n",
    "print(f\"Z-Stat: {stat}, P-score: {pval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our |Z-stat| is well below 1 and p-score is well above alpha, we fail to reject the null hypothesis and conclude that there is not a statistically significant difference in the proportion of customers who left the bank between our NaN and Known tenure groups.  \n",
    "\n",
    "Accordingly, for this project we will assume that Tenure is not a key determinate for churn. Because both mean (4.99 years) and mode (5 years) are roughly equal (indicating symmetrical distribution of Tenure years), we will substitute `NaN` values with 5.0 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tenure'] = df['Tenure'].fillna(5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation and Splitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data were split using a 3:1:1 ratio, resulting in 6000 entries for training and 2000 entries each of validation and final testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Set: (6000, 12)\n",
      "Shape of Validation Set: (2000, 12)\n",
      "Shape of Test Set: (2000, 12)\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1)\n",
    "df_ohe = pd.get_dummies(df_clean, drop_first=True)\n",
    "\n",
    "\n",
    "train_valid, df_test = train_test_split(df_ohe, test_size = 0.20, random_state=42)\n",
    "df_train, df_valid = train_test_split(train_valid, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "print(f'Shape of Training Set: {df_train.shape}')\n",
    "print(f'Shape of Validation Set: {df_valid.shape}')\n",
    "print(f'Shape of Test Set: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train = df_train.drop('Exited', axis=1)\n",
    "target_train = df_train['Exited']\n",
    "\n",
    "features_valid = df_valid.drop('Exited', axis=1)\n",
    "target_valid = df_valid['Exited']\n",
    "\n",
    "features_test = df_test.drop('Exited', axis=1)\n",
    "target_test = df_test['Exited']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model Training (Without Regard to Class Balance)\n",
    "\n",
    "Data were first fit using `GridSearchCV` on models with n_estimator of size 100, 200, 300, 500, 600, and 700 with tree depths 5 to 20 (increasing by 5's). The best model from this round (n-estimator size: 200, depth: 20) resulted in a F1 score of 0.609 when test against the validation data. While this as already past our threshold, futher testing were performed in attempt to improve the model.\n",
    "\n",
    "A second round of interations were performed. This time with n-estimator sizes from 125 to 275 (increasing by 25 step-wise) and with tree depths 5 to 20 (increasing by 5's). The best model from this round (n-estimator size: 250, depth: 20) resulted in a slightly improved accuracy score of 0.612 when test against the validation data. \n",
    "\n",
    "To maintain consistency with later model testing we overrode the '5-fold' method of `GridSearchCV` and explicitly passed it our prior separated training and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params (param_grid):\n",
    "    \n",
    "    X_combined = pd.concat([features_train, features_valid])\n",
    "    y_combined = pd.concat([target_train, target_valid])\n",
    "    \n",
    "    train_idx = np.arange(len(features_train))\n",
    "    valid_idx = np.arange(len(features_train), len(X_combined))\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(random_state=42),\n",
    "        param_grid=param_grid,\n",
    "        scoring=make_scorer(f1_score),\n",
    "        cv=[(train_idx, valid_idx)],\n",
    "        n_jobs=-2,\n",
    "        verbose=0,\n",
    "        refit=False\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_combined, y_combined)\n",
    "    \n",
    "    best_f1 = grid_search.best_score_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    return(\"Best F1:\", best_f1, \"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best F1:', 0.6085672082717873, 'Best params:', {'max_depth': 20, 'n_estimators': 200})\n"
     ]
    }
   ],
   "source": [
    "param_grid1 = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 600, 700],\n",
    "    'max_depth': [5, 10, 15, 20] \n",
    "}\n",
    "\n",
    "print(best_params (param_grid1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best F1:', 0.612184249628529, 'Best params:', {'max_depth': 20, 'n_estimators': 250})\n"
     ]
    }
   ],
   "source": [
    "param_grid2 = {\n",
    "    'n_estimators': [125, 150, 175, 200, 225, 250, 275],\n",
    "    'max_depth': [5, 10, 15, 20] \n",
    "}\n",
    "\n",
    "print(best_params (param_grid2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Adjusting for Class Imbalances\n",
    "\n",
    "From initial data exploration, we know that only 20.4% of customers left the bank. To account for this class inbalance, we maintained our prior hyperparmenters, this time balancing class weights and iterating through downsampling our negative case to 70%, 50%, and 20% of all cases; and upsampling positive cases by a factor of x2, x5, and x10.  \n",
    "\n",
    "When test against validation data class adjustments resulting in F1 Score of:  \n",
    "- Balanced Class Weights:  0.599\n",
    "- Downsample 0s to 70%:    0.618\n",
    "- Downsample 0s to 50%:    **0.637**\n",
    "- Downsample 0s to 20%:    0.571\n",
    "- Upsample 1s x2 F1 Score: 0.622\n",
    "- Upsample 1s x5 F1 Score: 0.616\n",
    "- Upsample 1s x10 F1 Score: 0.623\n",
    "\n",
    "Of these models, downsampling negative cases (customer retention) by 50% resulted in the highest F1 Score (0.637). \n",
    "\n",
    "### Balanced Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Class Weights F1 Score: 0.5907046476761619\n"
     ]
    }
   ],
   "source": [
    "balanced_model = RandomForestClassifier(random_state = 42, n_estimators = 250, max_depth= 20, class_weight='balanced')\n",
    "balanced_model.fit(features_train, target_train)\n",
    "predicted = balanced_model.predict(features_valid)\n",
    "bal_score = f1_score(target_valid, predicted)\n",
    "print(f'Balanced Class Weights F1 Score: {bal_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up and Down Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define methods downsample_zeros and upsample_ones\n",
    "\n",
    "def downsample_zeros(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=42)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=42)] + [target_ones])\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=42)\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "\n",
    "\n",
    "def upsample_ones(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=42)\n",
    "\n",
    "    return features_upsampled, target_upsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample 0s to 70% F1 Score: 0.617687074829932\n",
      "{0: 3338, 1: 1231}\n",
      "\n",
      "Downsample 0s to 50% F1 Score: 0.6371463714637147\n",
      "{0: 2384, 1: 1231}\n",
      "\n",
      "Downsample 0s to 20% F1 Score: 0.5709342560553633\n",
      "{1: 1231, 0: 954}\n",
      "\n",
      "Upsample 1s x2 F1 Score: 0.6218034993270525\n",
      "{0: 4769, 1: 2462}\n",
      "\n",
      "Upsample 1s x5 F1 Score: 0.6157826649417852\n",
      "{1: 6155, 0: 4769}\n",
      "\n",
      "Upsample 1s x10 F1 Score: 0.6229086229086229\n",
      "{1: 12310, 0: 4769}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rebal_methods = [\n",
    "    ('Downsample 0s to 70%',  'under', 0.7),\n",
    "    ('Downsample 0s to 50%',  'under', 0.5),\n",
    "    ('Downsample 0s to 20%',  'under', 0.2),\n",
    "    ('Upsample 1s x2',    'over',  2),\n",
    "    ('Upsample 1s x5',    'over',  5),\n",
    "    ('Upsample 1s x10',    'over',  10),\n",
    "]\n",
    "\n",
    "for name, method, frac in rebal_methods:\n",
    "    x_rebal, y_rebal = features_train, target_train\n",
    "\n",
    "    if method == 'under':\n",
    "        x_rebal, y_rebal = downsample_zeros(x_rebal, y_rebal,frac)\n",
    "        rebal_model = RandomForestClassifier(random_state = 42, n_estimators = 250, max_depth= 20)\n",
    "        rebal_model.fit(x_rebal, y_rebal)\n",
    "        predicted = rebal_model.predict(features_valid)\n",
    "        bal_score = score = f1_score(target_valid, predicted)\n",
    "        print(f'{name} F1 Score: {bal_score}')\n",
    "        print(y_rebal.value_counts().to_dict())\n",
    "        print()\n",
    "\n",
    "    elif method == 'over':\n",
    "        x_rebal, y_rebal = upsample_ones(x_rebal, y_rebal,frac)\n",
    "        rebal_model = RandomForestClassifier(random_state = 42, n_estimators = 250, max_depth= 20)\n",
    "        rebal_model.fit(x_rebal, y_rebal)\n",
    "        predicted = rebal_model.predict(features_valid)\n",
    "        bal_score = score = f1_score(target_valid, predicted)\n",
    "        print(f'{name} F1 Score: {bal_score}')\n",
    "        print(y_rebal.value_counts().to_dict())\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Adjustments\n",
    "\n",
    "To further assess the percision and recall of our models, we iterated through thresholds for predicting the positive case -- 0.0 to 1.0 stepwise by 0.0125. The ROC curve was also plotted for our the model without regard to class balance.\n",
    "\n",
    "### Adjustments without Regard to Class Balance\n",
    "\n",
    "The AUC_ROC for our model without adjusting for class balance was 0.861, showing that the model is well able to discriminate between cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC for Classifier w/ Estimators = 250  Depth = 20 : 0.8614659666692603\n"
     ]
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(random_state = 42, n_estimators = 250, max_depth= 20)\n",
    "\n",
    "model_forest.fit(features_train, target_train)\n",
    "\n",
    "probabilities_valid = model_forest.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)\n",
    "\n",
    "plt.figure(figsize=[4,3])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title('ROC curve') \n",
    "plt.show()\n",
    "        \n",
    "print (f'AUC-ROC for Classifier w/ Estimators = 250  Depth = 20 : {auc_roc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.388    F1 Score:    0.6343949044585987\n",
      "TPR= 0.6029055690072639    FPR = 0.07750472589792061\n"
     ]
    }
   ],
   "source": [
    "best_threshold = 0.5\n",
    "best_f1 = 0 \n",
    "\n",
    "for threshold in np.arange(0, 1, 0.0125):\n",
    "    predicted = probabilities_one_valid > threshold\n",
    "    tresh_f1 = f1_score(target_valid, predicted)\n",
    "    if tresh_f1 > best_f1:\n",
    "        best_f1 = tresh_f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f'Best Threshold: {best_threshold.round(3)}    F1 Score:    {best_f1}')\n",
    "\n",
    "\n",
    "predicted = probabilities_one_valid > best_threshold\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(target_valid, predicted).ravel()\n",
    "\n",
    "bestf1_TPR = tp / (tp + fn)\n",
    "bestf1_FPR = fp / (fp + tn)\n",
    "\n",
    "\n",
    "print(f'TPR= {bestf1_TPR}    FPR = {bestf1_FPR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting Thresholds and Class Balance\n",
    "\n",
    "Smaller threshold increases (0.0 to 1.0 stepwise by 0.00625) was then applied to each of our class balance readjustments. All results are presented below, however notable models include:\n",
    "\n",
    "- Downsampling 0s to 70% with max F1 at threshold of 0.45\n",
    "    - F1 Score:    0.635 &  AUC-ROC:  0.863\n",
    "- Downsampling 0s to 50% with with with max F1 at threshold of 0.5125\n",
    "    - F1 Score:    0.642 &    AUC-ROC:  0.862\n",
    "- Upsampling 1s x10 with a with max F1 at threshold of 0.49375\n",
    "    - F1 Score:    0.6309067688378034  &  AUC_ROC:  0.8610387668572284\n",
    "\n",
    "While downsampling our negative cases to 50% of training data resulted in the highest F1 score, it did so with a max F1 at a threshold of 0.5125 meaning that it was less inclined to identify positive cases (the metric we want). Because we want to identify all many customers as possible before they leave the bank, we are willing to accept a model that is more aggresive at identifying positive cases. \n",
    "\n",
    "Accordingly, downsampling the negative cases to 70% results in a max F1 at a threshold of 0.45. This model is more inclined to predict customers leaving the bank. \n",
    "\n",
    "Notably, upsampling positive cases did not result in notable model improvements until positive cases were multiplied 10 fold {1: 12310, 0: 4769}. This increases the risk of overfitting, so unsampled models were not considered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold using Balanced Classes:     0.95625    F1 Score:    0.004830917874396135\n",
      "AUC_ROC:  0.8654618106253749\n"
     ]
    }
   ],
   "source": [
    "probabilities_bal = balanced_model.predict_proba(features_valid)\n",
    "probabilities_one_bal = probabilities_bal[:, 1]\n",
    "\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in np.arange(0, 1, 0.00625):\n",
    "        predicted = probabilities_one_bal > threshold\n",
    "        bal_f1 = f1_score(target_valid, predicted)\n",
    "        if bal_f1 > best_f1:\n",
    "            best_f1 = tresh_f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "print(f'Best Threshold using Balanced Classes:     {best_threshold.round(6)}    F1 Score:    {best_f1}')\n",
    "print('AUC_ROC: ',roc_auc_score(target_valid, probabilities_one_bal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold using Downsample 0s to 70%:     0.45    F1 Score:    0.6345177664974619\n",
      "AUC_ROC:  0.8625660061852432\n",
      "\n",
      "Best Threshold using Downsample 0s to 50%:     0.5125    F1 Score:    0.6416978776529338\n",
      "AUC_ROC:  0.8622646777463989\n",
      "\n",
      "Best Threshold using Downsample 0s to 20%:     0.73125    F1 Score:    0.6034255599472991\n",
      "AUC_ROC:  0.8522323478749099\n",
      "\n",
      "Best Threshold using Upsample 1s x2:     0.46875    F1 Score:    0.6284224250325945\n",
      "AUC_ROC:  0.8594680446912032\n",
      "\n",
      "Best Threshold using Upsample 1s x5:     0.4125    F1 Score:    0.62877030162413\n",
      "AUC_ROC:  0.8636568914195392\n",
      "\n",
      "Best Threshold using Upsample 1s x10:     0.49375    F1 Score:    0.6309067688378033\n",
      "AUC_ROC:  0.8610387668572284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, method, frac in rebal_methods:\n",
    "    x_rebal, y_rebal = features_train, target_train\n",
    "    if method == 'under':\n",
    "        x_rebal, y_rebal = downsample_zeros(x_rebal, y_rebal,frac)\n",
    "        rebal_model = RandomForestClassifier(random_state = 42, n_estimators = 250, max_depth= 20)\n",
    "        rebal_model.fit(x_rebal, y_rebal)\n",
    "\n",
    "    elif method == 'over':\n",
    "        x_rebal, y_rebal = upsample_ones(x_rebal, y_rebal,frac)\n",
    "        rebal_model = RandomForestClassifier(random_state = 42, n_estimators = 250, max_depth= 20)\n",
    "        rebal_model.fit(x_rebal, y_rebal)\n",
    "\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0 \n",
    "\n",
    "    probabilities_valid = rebal_model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    \n",
    "    for threshold in np.arange(0, 1, 0.00625):\n",
    "        predicted = probabilities_one_valid > threshold\n",
    "        tresh_f1 = f1_score(target_valid, predicted)\n",
    "        if tresh_f1 > best_f1:\n",
    "            best_f1 = tresh_f1\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    print(f'Best Threshold using {name}:     {best_threshold.round(6)}    F1 Score:    {best_f1}')\n",
    "    print('AUC_ROC: ',roc_auc_score(target_valid, probabilities_one_valid))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 of Final Model: 0.6197916666666666\n",
      "Validation TPR= 0.605    Validation FPR = 0.079\n",
      "Final Test TPR = 0.606    Final Test FPR = 0.085\n"
     ]
    }
   ],
   "source": [
    "x_rebal, y_rebal = downsample_zeros(features_train, target_train, 0.7)\n",
    "final_model = RandomForestClassifier(random_state = 42, n_estimators = 250, max_depth=20)\n",
    "final_model.fit(x_rebal, y_rebal)\n",
    "\n",
    "probabilities_test = final_model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "predicted_test = probabilities_one_test > 0.45\n",
    "final_f1 = f1_score(target_test, predicted_test)\n",
    "\n",
    "print(f'F1 of Final Model: {final_f1}')\n",
    "\n",
    "probabilities_valid = final_model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "predicted_valid = probabilities_one_valid > 0.45\n",
    "\n",
    "val_tn, val_fp, val_fn, val_tp = confusion_matrix(target_valid, predicted_valid).ravel()\n",
    "val_TPR = val_tp / (val_tp + val_fn)\n",
    "val_FPR = val_fp / (val_fp + val_tn)\n",
    "print(f'Validation TPR= {val_TPR.round(3)}    Validation FPR = {val_FPR.round(3)}')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(target_test, predicted_test).ravel()\n",
    "test_TPR = tp / (tp + fn)\n",
    "test_FPR = fp / (fp + tn)\n",
    "\n",
    "print(f'Final Test TPR = {test_TPR.round(3)}    Final Test FPR = {test_FPR.round(3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "For the reasons mentioned above, the final parameters chosen for our model were:\n",
    "- Downsampling negative cases to 70% of total training data\n",
    "- n-estimators = 250\n",
    "- max_depth = 20\n",
    "- Prediction Threshold for Positive Case: 0.45\n",
    "\n",
    "When test against the reserved testing data, our model yeildied a F1 score of 0.620, exceeding our accuracy measure of 0.59.\n",
    "\n",
    "While our score is lower than prior F1 tests, this can be attributed to a higher FPR (0.085 v 0.079 from validation testing) and a slightly improved TPR (0.606 v 0.605 from validation testing). In the context of our project, where wish to identify more potential customers who may leave, this is a desirable outcome. As similar positive cases were correctly identified in validation and final testing, our model passes the sanity test. \n",
    "\n",
    "Having passed final accuracy and sanity testing, out model is ready for delivery to our retention project teams. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
